{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7RchVVCwyc8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TGW9_yCeydrh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pkhS2zjGmCtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc1363aa-8158-411c-c719-ae49beb1af17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Math  Reading  Writing\n",
            "0    48       68       63\n",
            "1    62       81       72\n",
            "2    79       80       78\n",
            "3    76       83       79\n",
            "4    59       64       62\n",
            "     Math  Reading  Writing\n",
            "995    72       74       70\n",
            "996    73       86       90\n",
            "997    89       87       94\n",
            "998    83       82       78\n",
            "999    66       66       72\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Math     1000 non-null   int64\n",
            " 1   Reading  1000 non-null   int64\n",
            " 2   Writing  1000 non-null   int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 23.6 KB\n",
            "None\n",
            "              Math      Reading      Writing\n",
            "count  1000.000000  1000.000000  1000.000000\n",
            "mean     67.290000    69.872000    68.616000\n",
            "std      15.085008    14.657027    15.241287\n",
            "min      13.000000    19.000000    14.000000\n",
            "25%      58.000000    60.750000    58.000000\n",
            "50%      68.000000    70.000000    69.500000\n",
            "75%      78.000000    81.000000    79.000000\n",
            "max     100.000000   100.000000   100.000000\n",
            "Math       0\n",
            "Reading    0\n",
            "Writing    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataframe = pd.read_csv(\"/content/drive/MyDrive/Ai/student.csv\")\n",
        "\n",
        "#Top 5 dataset\n",
        "print(dataframe.head())\n",
        "#Bottom 5 dataset\n",
        "print(dataframe.tail())\n",
        "#Information of the dataset\n",
        "print(dataframe.info())\n",
        "#Descriptive info of the datset\n",
        "print(dataframe.describe())\n",
        "#checking null values in the dataset\n",
        "print(dataframe.isnull().sum())\n",
        "#Splitting the data into Feature(X) and Label(Y)\n",
        "X = dataframe.drop(columns = [\"Writing\"]).values\n",
        "Y = dataframe[\"Writing\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 2"
      ],
      "metadata": {
        "id": "YcYkoKR0yfPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assuming there is no bias\n",
        "# X shape: (m, n)\n",
        "# Y shape: (m, 1)\n",
        "print(f\"X shape: {X.shape}\")\n",
        "print(f\"Y shape: {Y.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HK98a8hyxuI",
        "outputId": "b49ee9b8-b0d8-49e6-912b-8192e0b2d416"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (1000, 2)\n",
            "Y shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 3"
      ],
      "metadata": {
        "id": "Mi-L6zywzKmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and test sets (80% train, 20% test)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shape of the resulting splits\n",
        "print(f\"Training Features shape: {X_train.shape}\")\n",
        "print(f\"Test Features shape: {X_test.shape}\")\n",
        "print(f\"Training Labels shape: {Y_train.shape}\")\n",
        "print(f\"Test Labels shape: {Y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLh4lROOzMkl",
        "outputId": "6fca576f-f61a-4798-d294-eb4c2e8293b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features shape: (800, 2)\n",
            "Test Features shape: (200, 2)\n",
            "Training Labels shape: (800,)\n",
            "Test Labels shape: (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.2 Step -2- Build a Cost Function:"
      ],
      "metadata": {
        "id": "mMoeA_4p0JYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 4"
      ],
      "metadata": {
        "id": "p5P1xaf40LzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Feature matrix (3 samples, 2 features)\n",
        "X = np.array([[1, 2],\n",
        "              [3, 4],\n",
        "              [5, 6]])\n",
        "\n",
        "# True labels\n",
        "Y = np.array([3, 7, 11])\n",
        "\n",
        "# Weights\n",
        "W = np.array([1, 1])\n",
        "\n",
        "# Hypothesis (predicted values)\n",
        "H = X @ W  # Matrix multiplication\n",
        "\n",
        "# Mean Squared Error cost function\n",
        "cost = np.mean((H - Y) ** 2) / 2\n",
        "\n",
        "print(\"Predictions:\", H)\n",
        "print(\"Cost:\", cost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31xWilcd0PGQ",
        "outputId": "d32ebdaf-9e4f-419c-d44f-9eaede36dda7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [ 3  7 11]\n",
            "Cost: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 5"
      ],
      "metadata": {
        "id": "HKItYhFC06R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the cost fxn\n",
        "X_test = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "Y_test = np.array([3, 7, 11])\n",
        "W_test = np.array([1, 1])\n",
        "cost = cost_function(X_test, Y_test, W_test)\n",
        "if cost == 0:\n",
        "  print(\"Proceed Further\")\n",
        "else:\n",
        "  print(\"something went wrong: Reimplement a cost function\")\n",
        "print(\"Cost function output:\", cost_function(X_test, Y_test, W_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDxFE10x0-zc",
        "outputId": "361ff79f-32e8-4b82-ef1f-36756078222b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proceed Further\n",
            "Cost function output: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.3 Step -3- Gradient Descent for Simple Linear Regression:"
      ],
      "metadata": {
        "id": "SShtm_Zf1OEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 6"
      ],
      "metadata": {
        "id": "b8sfZpVA1df0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "  cost_history = [0] * iterations\n",
        "  m = len(Y)\n",
        "  W_update = W.copy()\n",
        "  for iteration in range(iterations):\n",
        "    Y_pred = X.dot(W_update)\n",
        "    loss = Y_pred - Y\n",
        "    dw = (1/m)*X.T.dot(loss)\n",
        "    W_update = W_update - alpha * dw\n",
        "    cost = cost_function(X, Y, W_update)\n",
        "    cost_history[iteration] = cost\n",
        "  return W_update, cost_history\n",
        "\n"
      ],
      "metadata": {
        "id": "NCClCftr1bnA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 7"
      ],
      "metadata": {
        "id": "8I_mWKoL1yuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)  # shape: (100, 3)\n",
        "Y = np.random.rand(100)     # shape: (100,)\n",
        "W = np.random.rand(3)       # shape: (3,)\n",
        "\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"Cost History:\", cost_history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owzhexeB10Sf",
        "outputId": "770056a8-a38c-432d-b4f2-c88852b10c5d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Parameters: [0.20551667 0.54295081 0.10388027]\n",
            "Cost History: [np.float64(0.10711197094660153), np.float64(0.10634880599939901), np.float64(0.10559826315680618), np.float64(0.10486012948320558), np.float64(0.1041341956428534), np.float64(0.10342025583900626), np.float64(0.1027181077540776), np.float64(0.1020275524908062), np.float64(0.10134839451441931), np.float64(0.1006804415957737), np.float64(0.1000235047554587), np.float64(0.09937739820884377), np.float64(0.09874193931205609), np.float64(0.09811694850887098), np.float64(0.09750224927850094), np.float64(0.0968976680842672), np.float64(0.09630303432313951), np.float64(0.09571818027612913), np.float64(0.09514294105952065), np.float64(0.09457715457692842), np.float64(0.09402066147216397), np.float64(0.09347330508290017), np.float64(0.09293493139511913), np.float64(0.09240538899833017), np.float64(0.09188452904154543), np.float64(0.0913722051899995), np.float64(0.09086827358260123), np.float64(0.09037259279010502), np.float64(0.08988502377398919), np.float64(0.08940542984603007), np.float64(0.08893367662855953), np.float64(0.08846963201539432), np.float64(0.08801316613342668), np.float64(0.08756415130486386), np.float64(0.08712246201010665), np.float64(0.08668797485125508), np.float64(0.08626056851623207), np.float64(0.08584012374351278), np.float64(0.08542652328745133), np.float64(0.08501965188419301), np.float64(0.0846193962181636), np.float64(0.08422564488912489), np.float64(0.08383828837978763), np.float64(0.08345721902397185), np.float64(0.08308233097530582), np.float64(0.08271352017645425), np.float64(0.08235068432886682), np.float64(0.08199372286303817), np.float64(0.08164253690927113), np.float64(0.08129702926893387), np.float64(0.08095710438620353), np.float64(0.08062266832028739), np.float64(0.08029362871811391), np.float64(0.07996989478748553), np.float64(0.0796513772706855), np.float64(0.07933798841853089), np.float64(0.07902964196486459), np.float64(0.07872625310147845), np.float64(0.07842773845346054), np.float64(0.07813401605495938), np.float64(0.0778450053253578), np.float64(0.0775606270458499), np.float64(0.07728080333641404), np.float64(0.07700545763317514), np.float64(0.07673451466614989), np.float64(0.07646790043736812), np.float64(0.07620554219936448), np.float64(0.07594736843403344), np.float64(0.07569330883184205), np.float64(0.07544329427139428), np.float64(0.07519725679934074), np.float64(0.07495512961062821), np.float64(0.07471684702908327), np.float64(0.07448234448832412), np.float64(0.0742515585129952), np.float64(0.07402442670031911), np.float64(0.0738008877019607), np.float64(0.07358088120619749), np.float64(0.0733643479203919), np.float64(0.07315122955375959), np.float64(0.07294146880042966), np.float64(0.07273500932279067), np.float64(0.07253179573511871), np.float64(0.07233177358748233), np.float64(0.0721348893499193), np.float64(0.07194109039688139), np.float64(0.07175032499194182), np.float64(0.07156254227276149), np.float64(0.07137769223630935), np.float64(0.07119572572433286), np.float64(0.07101659440907385), np.float64(0.07084025077922623), np.float64(0.070666648126131), np.float64(0.07049574053020462), np.float64(0.07032748284759716), np.float64(0.07016183069707572), np.float64(0.0699987404471299), np.float64(0.06983816920329523), np.float64(0.06968007479569092), np.float64(0.06952441576676843), np.float64(0.06937115135926715), np.float64(0.06922024150437375), np.float64(0.06907164681008185), np.float64(0.06892532854974835), np.float64(0.0687812486508435), np.float64(0.06863936968389095), np.float64(0.06849965485159508), np.float64(0.06836206797815195), np.float64(0.06822657349874123), np.float64(0.06809313644919561), np.float64(0.067961722455845), np.float64(0.06783229772553254), np.float64(0.06770482903579932), np.float64(0.06757928372523506), np.float64(0.06745562968399212), np.float64(0.06733383534445969), np.float64(0.06721386967209597), np.float64(0.06709570215641501), np.float64(0.06697930280212627), np.float64(0.06686464212042395), np.float64(0.06675169112042348), np.float64(0.0666404213007429), np.float64(0.06653080464122665), np.float64(0.06642281359480932), np.float64(0.06631642107951677), np.float64(0.06621160047060279), np.float64(0.06610832559281864), np.float64(0.06600657071281309), np.float64(0.0659063105316614), np.float64(0.06580752017752023), np.float64(0.06571017519840698), np.float64(0.06561425155510119), np.float64(0.06551972561416586), np.float64(0.06542657414108709), np.float64(0.06533477429352925), np.float64(0.06524430361470467), np.float64(0.06515514002685512), np.float64(0.06506726182484374), np.float64(0.06498064766985515), np.float64(0.06489527658320228), np.float64(0.06481112794023773), np.float64(0.06472818146436811), np.float64(0.0646464172211699), np.float64(0.06456581561260431), np.float64(0.06448635737133043), np.float64(0.0644080235551142), np.float64(0.06433079554133217), np.float64(0.06425465502156798), np.float64(0.06417958399630046), np.float64(0.06410556476968135), np.float64(0.06403257994440141), np.float64(0.0639606124166433), np.float64(0.06388964537111992), np.float64(0.06381966227619645), np.float64(0.06375064687909507), np.float64(0.06368258320118077), np.float64(0.06361545553332655), np.float64(0.06354924843135755), np.float64(0.06348394671157162), np.float64(0.06341953544633615), np.float64(0.06335599995975896), np.float64(0.06329332582343267), np.float64(0.06323149885225086), np.float64(0.06317050510029515), np.float64(0.06311033085679153), np.float64(0.06305096264213547), np.float64(0.06299238720398384), np.float64(0.0629345915134133), np.float64(0.06287756276114324), np.float64(0.06282128835382297), np.float64(0.0627657559103815), np.float64(0.06271095325843898), np.float64(0.06265686843077901), np.float64(0.06260348966188053), np.float64(0.06255080538450809), np.float64(0.06249880422636036), np.float64(0.06244747500677472), np.float64(0.06239680673348793), np.float64(0.06234678859945137), np.float64(0.06229740997970036), np.float64(0.0622486604282762), np.float64(0.06220052967520031), np.float64(0.062153007623499706), np.float64(0.062106084346282515), np.float64(0.062059750083863094), np.float64(0.06201399524093575), np.float64(0.06196881038379625), np.float64(0.061924186237610215), np.float64(0.06188011368372787), np.float64(0.0618365837570441), np.float64(0.06179358764340313), np.float64(0.061751116677047156), np.float64(0.06170916233810801), np.float64(0.0616677162501414), np.float64(0.06162677017770278), np.float64(0.061586316023964055), np.float64(0.0615463458283708), np.float64(0.06150685176433905), np.float64(0.06146782613699094), np.float64(0.0614292613809287), np.float64(0.061391150058046254), np.float64(0.06135348485537795), np.float64(0.06131625858298352), np.float64(0.061279464171868706), np.float64(0.06124309467194143), np.float64(0.061207143250002184), np.float64(0.06117160318776841), np.float64(0.06113646787993252), np.float64(0.061101730832252524), np.float64(0.06106738565967507), np.float64(0.06103342608449018), np.float64(0.06099984593451716), np.float64(0.06096663914132128), np.float64(0.0609337997384604), np.float64(0.0609013218597616), np.float64(0.06086919973762659), np.float64(0.06083742770136588), np.float64(0.06080600017556133), np.float64(0.06077491167845612), np.float64(0.06074415682037193), np.float64(0.06071373030215326), np.float64(0.060683626913637524), np.float64(0.06065384153215141), np.float64(0.06062436912103256), np.float64(0.0605952047281761), np.float64(0.06056634348460599), np.float64(0.060537780603070336), np.float64(0.060509511376660545), np.float64(0.0604815311774538), np.float64(0.060453835455178496), np.float64(0.06042641973590228), np.float64(0.06039927962074216), np.float64(0.060372410784596583), np.float64(0.060345808974898815), np.float64(0.06031947001039151), np.float64(0.06029338977992186), np.float64(0.06026756424125725), np.float64(0.060241989419920934), np.float64(0.06021666140804729), np.float64(0.0601915763632565), np.float64(0.06016673050754826), np.float64(0.060142120126214255), np.float64(0.06011774156676883), np.float64(0.06009359123789796), np.float64(0.06006966560842588), np.float64(0.06004596120629915), np.float64(0.060022474617588105), np.float64(0.059999202485504784), np.float64(0.059976141509438), np.float64(0.05995328844400421), np.float64(0.05993064009811483), np.float64(0.05990819333405906), np.float64(0.059885945066602345), np.float64(0.059863892262100066), np.float64(0.059842031937626106), np.float64(0.059820361160116395), np.float64(0.05979887704552664), np.float64(0.05977757675800453), np.float64(0.05975645750907579), np.float64(0.05973551655684408), np.float64(0.0597147512052044), np.float64(0.05969415880306974), np.float64(0.05967373674361096), np.float64(0.05965348246350928), np.float64(0.05963339344222168), np.float64(0.059613467201258485), np.float64(0.059593701303473294), np.float64(0.05957409335236496), np.float64(0.05955464099139111), np.float64(0.05953534190329372), np.float64(0.059516193809435625), np.float64(0.0594971944691485), np.float64(0.0594783416790919), np.float64(0.05945963327262296), np.float64(0.0594410671191769), np.float64(0.05942264112365792), np.float64(0.05940435322584049), np.float64(0.059386201399780576), np.float64(0.059368183653237094), np.float64(0.059350298027102844), np.float64(0.05933254259484533), np.float64(0.05931491546195686), np.float64(0.05929741476541398), np.float64(0.0592800386731462), np.float64(0.05926278538351338), np.float64(0.05924565312479226), np.float64(0.05922864015467154), np.float64(0.059211744759755505), np.float64(0.059194965255076046), np.float64(0.05917829998361292), np.float64(0.05916174731582212), np.float64(0.059145305649172315), np.float64(0.059128973407688926), np.float64(0.059112749041506096), np.float64(0.05909663102642617), np.float64(0.05908061786348662), np.float64(0.059064708078534194), np.float64(0.05904890022180654), np.float64(0.05903319286752055), np.float64(0.05901758461346795), np.float64(0.05900207408061755), np.float64(0.058986659912724324), np.float64(0.05897134077594505), np.float64(0.058956115358460404), np.float64(0.05894098237010357), np.float64(0.05892594054199501), np.float64(0.05891098862618344), np.float64(0.05889612539529293), np.float64(0.05888134964217589), np.float64(0.05886666017957195), np.float64(0.058852055839772675), np.float64(0.05883753547429179), np.float64(0.058823097953541174), np.float64(0.058808742166512155), np.float64(0.05879446702046235), np.float64(0.058780271440607684), np.float64(0.05876615436981961), np.float64(0.05875211476832761), np.float64(0.05873815161342641), np.float64(0.05872426389918856), np.float64(0.058710450636181515), np.float64(0.05869671085118971), np.float64(0.058683043586941104), np.float64(0.058669447901838714), np.float64(0.05865592286969638), np.float64(0.05864246757947903), np.float64(0.05862908113504752), np.float64(0.05861576265490756), np.float64(0.058602511271963004), np.float64(0.05858932613327336), np.float64(0.058576206399815284), np.float64(0.05856315124624814), np.float64(0.05855015986068357), np.float64(0.05853723144445888), np.float64(0.05852436521191438), np.float64(0.05851156039017436), np.float64(0.0584988162189318), np.float64(0.05848613195023677), np.float64(0.05847350684828838), np.float64(0.058460940189230176), np.float64(0.05844843126094919), np.float64(0.05843597936287807), np.float64(0.05842358380580092), np.float64(0.05841124391166213), np.float64(0.05839895901337858), np.float64(0.05838672845465502), np.float64(0.05837455158980245), np.float64(0.05836242778355972), np.float64(0.05835035641091811), np.float64(0.05833833685694878), np.float64(0.05832636851663321), np.float64(0.05831445079469655), np.float64(0.05830258310544367), np.float64(0.05829076487259809), np.float64(0.05827899552914358), np.float64(0.05826727451716845), np.float64(0.058255601287712386), np.float64(0.0582439753006161), np.float64(0.058232396024373266), np.float64(0.05822086293598511), np.float64(0.058209375520817355), np.float64(0.058197933272459756), np.float64(0.05818653569258779), np.float64(0.05817518229082684), np.float64(0.058163872584618616), np.float64(0.05815260609908985), np.float64(0.058141382366923164), np.float64(0.058130200928230166), np.float64(0.058119061330426776), np.float64(0.058107963128110396), np.float64(0.05809690588293942), np.float64(0.058085889163514745), np.float64(0.058074912545263056), np.float64(0.058063975610322414), np.float64(0.058053077947429504), np.float64(0.05804221915180897), np.float64(0.05803139882506447), np.float64(0.05802061657507169), np.float64(0.0580098720158732), np.float64(0.05799916476757483), np.float64(0.057988494456244134), np.float64(0.057977860713810364), np.float64(0.057967263177966154), np.float64(0.05795670149207094), np.float64(0.05794617530505593), np.float64(0.05793568427133074), np.float64(0.057925228050691516), np.float64(0.057914806308230836), np.float64(0.057904418714248757), np.float64(0.057894064944165734), np.float64(0.05788374467843681), np.float64(0.05787345760246728), np.float64(0.057863203406529826), np.float64(0.05785298178568306), np.float64(0.05784279243969133), np.float64(0.057832635072946004), np.float64(0.05782250939438805), np.float64(0.0578124151174319), np.float64(0.05780235195989063), np.float64(0.057792319643902336), np.float64(0.05778231789585793), np.float64(0.0577723464463298), np.float64(0.05776240503000217), np.float64(0.05775249338560223), np.float64(0.05774261125583255), np.float64(0.05773275838730474), np.float64(0.05772293453047407), np.float64(0.05771313943957533), np.float64(0.0577033728725597), np.float64(0.057693634591032654), np.float64(0.057683924360193005), np.float64(0.05767424194877295), np.float64(0.05766458712897906), np.float64(0.05765495967643434), np.float64(0.057645359370121226), np.float64(0.05763578599232564), np.float64(0.057626239328581796), np.float64(0.05761671916761811), np.float64(0.05760722530130401), np.float64(0.05759775752459752), np.float64(0.057588315635493874), np.float64(0.057578899434974906), np.float64(0.05756950872695933), np.float64(0.05756014331825381), np.float64(0.05755080301850501), np.float64(0.057541487640152184), np.float64(0.05753219699838088), np.float64(0.057522930911077144), np.float64(0.057513689198782685), np.float64(0.05750447168465076), np.float64(0.05749527819440267), np.float64(0.057486108556285255), np.float64(0.05747696260102877), np.float64(0.05746784016180581), np.float64(0.05745874107419066), np.float64(0.05744966517611951), np.float64(0.05744061230785123), np.float64(0.05743158231192885), np.float64(0.05742257503314173), np.float64(0.057413590318488285), np.float64(0.05740462801713937), np.float64(0.057395687980402336), np.float64(0.05738677006168561), np.float64(0.05737787411646401), np.float64(0.057369000002244354), np.float64(0.05736014757853204), np.float64(0.05735131670679789), np.float64(0.057342507250445686), np.float64(0.05733371907478018), np.float64(0.05732495204697581), np.float64(0.057316206036045626), np.float64(0.05730748091281111), np.float64(0.057298776549872255), np.float64(0.05729009282157824), np.float64(0.05728142960399854), np.float64(0.05727278677489465), np.float64(0.05726416421369212), np.float64(0.05725556180145319), np.float64(0.05724697942084986), np.float64(0.0572384169561373), np.float64(0.05722987429312795), np.float64(0.05722135131916572), np.float64(0.05721284792310103), np.float64(0.05720436399526589), np.float64(0.0571958994274496), np.float64(0.057187454112874896), np.float64(0.05717902794617434), np.float64(0.05717062082336728), np.float64(0.057162232641836994), np.float64(0.05715386330030848), np.float64(0.05714551269882637), np.float64(0.05713718073873334), np.float64(0.05712886732264895), np.float64(0.05712057235444866), np.float64(0.05711229573924336), np.float64(0.05710403738335914), np.float64(0.0570957971943175), np.float64(0.05708757508081579), np.float64(0.057079370952708035), np.float64(0.057071184720986066), np.float64(0.05706301629776107), np.float64(0.057054865596245175), np.float64(0.057046732530733744), np.float64(0.05703861701658757), np.float64(0.05703051897021566), np.float64(0.05702243830905818), np.float64(0.057014374951569684), np.float64(0.057006328817202634), np.float64(0.05699829982639134), np.float64(0.05699028790053585), np.float64(0.05698229296198646), np.float64(0.05697431493402824), np.float64(0.05696635374086599), np.float64(0.05695840930760929), np.float64(0.056950481560257914), np.float64(0.0569425704256875), np.float64(0.0569346758316353), np.float64(0.05692679770668645), np.float64(0.05691893598026014), np.float64(0.05691109058259633), np.float64(0.05690326144474244), np.float64(0.05689544849854041), np.float64(0.056887651676613984), np.float64(0.05687987091235604), np.float64(0.056872106139916355), np.float64(0.05686435729418944), np.float64(0.05685662431080263), np.float64(0.0568489071261043), np.float64(0.05684120567715239), np.float64(0.056833519901703065), np.float64(0.05682584973819958), np.float64(0.05681819512576124), np.float64(0.05681055600417275), np.float64(0.056802932313873525), np.float64(0.056795323995947306), np.float64(0.056787730992111936), np.float64(0.05678015324470926), np.float64(0.05677259069669528), np.float64(0.05676504329163035), np.float64(0.05675751097366966), np.float64(0.05674999368755382), np.float64(0.05674249137859953), np.float64(0.05673500399269066), np.float64(0.05672753147626912), np.float64(0.056720073776326194), np.float64(0.05671263084039382), np.float64(0.056705202616536096), np.float64(0.05669778905334098), np.float64(0.05669039009991206), np.float64(0.05668300570586036), np.float64(0.05667563582129657), np.float64(0.056668280396823104), np.float64(0.05666093938352648), np.float64(0.05665361273296975), np.float64(0.056646300397185066), np.float64(0.05663900232866641), np.float64(0.05663171848036241), np.float64(0.05662444880566923), np.float64(0.05661719325842369), np.float64(0.056609951792896414), np.float64(0.05660272436378514), np.float64(0.05659551092620811), np.float64(0.056588311435697584), np.float64(0.05658112584819342), np.float64(0.05657395412003692), np.float64(0.05656679620796451), np.float64(0.05655965206910184), np.float64(0.05655252166095763), np.float64(0.05654540494141801), np.float64(0.056538301868740586), np.float64(0.05653121240154893), np.float64(0.056524136498826864), np.float64(0.056517074119913024), np.float64(0.05651002522449555), np.float64(0.05650298977260663), np.float64(0.05649596772461748), np.float64(0.056488959041233064), np.float64(0.05648196368348717), np.float64(0.05647498161273735), np.float64(0.0564680127906601), np.float64(0.056461057179246134), np.float64(0.05645411474079556), np.float64(0.05644718543791332), np.float64(0.05644026923350467), np.float64(0.056433366090770515), np.float64(0.05642647597320331), np.float64(0.05641959884458242), np.float64(0.05641273466897008), np.float64(0.05640588341070717), np.float64(0.05639904503440896), np.float64(0.05639221950496121), np.float64(0.05638540678751615), np.float64(0.05637860684748858), np.float64(0.056371819650551894), np.float64(0.05636504516263454), np.float64(0.05635828334991603), np.float64(0.05635153417882347), np.float64(0.05634479761602789), np.float64(0.05633807362844066), np.float64(0.05633136218321008), np.float64(0.056324663247717996), np.float64(0.05631797678957624), np.float64(0.05631130277662355), np.float64(0.05630464117692215), np.float64(0.056297991958754665), np.float64(0.05629135509062089), np.float64(0.056284730541234666), np.float64(0.05627811827952098), np.float64(0.05627151827461283), np.float64(0.0562649304958483), np.float64(0.05625835491276777), np.float64(0.05625179149511093), np.float64(0.05624524021281401), np.float64(0.05623870103600713), np.float64(0.05623217393501149), np.float64(0.05622565888033667), np.float64(0.05621915584267811), np.float64(0.05621266479291449), np.float64(0.056206185702105234), np.float64(0.05619971854148787), np.float64(0.05619326328247578), np.float64(0.05618681989665565), np.float64(0.05618038835578517), np.float64(0.05617396863179063), np.float64(0.05616756069676472), np.float64(0.05616116452296419), np.float64(0.05615478008280768), np.float64(0.05614840734887347), np.float64(0.05614204629389748), np.float64(0.05613569689077096), np.float64(0.0561293591125386), np.float64(0.056123032932396344), np.float64(0.05611671832368947), np.float64(0.05611041525991056), np.float64(0.05610412371469758), np.float64(0.056097843661832), np.float64(0.05609157507523687), np.float64(0.05608531792897493), np.float64(0.05607907219724691), np.float64(0.056072837854389615), np.float64(0.05606661487487427), np.float64(0.05606040323330473), np.float64(0.056054202904415734), np.float64(0.05604801386307135), np.float64(0.056041836084263226), np.float64(0.056035669543109), np.float64(0.056029514214850695), np.float64(0.05602337007485319), np.float64(0.05601723709860266), np.float64(0.05601111526170498), np.float64(0.05600500453988435), np.float64(0.05599890490898177), np.float64(0.05599281634495359), np.float64(0.055986738823870105), np.float64(0.055980672321914095), np.float64(0.055974616815379595), np.float64(0.055968572280670384), np.float64(0.055962538694298715), np.float64(0.05595651603288404), np.float64(0.05595050427315166), np.float64(0.0559445033919315), np.float64(0.05593851336615685), np.float64(0.05593253417286313), np.float64(0.05592656578918666), np.float64(0.05592060819236354), np.float64(0.05591466135972839), np.float64(0.05590872526871329), np.float64(0.05590279989684662), np.float64(0.05589688522175184), np.float64(0.055890981221146614), np.float64(0.05588508787284151), np.float64(0.055879205154739084), np.float64(0.05587333304483278), np.float64(0.05586747152120588), np.float64(0.055861620562030555), np.float64(0.05585578014556684), np.float64(0.05584995025016163), np.float64(0.05584413085424776), np.float64(0.05583832193634303), np.float64(0.0558325234750493), np.float64(0.0558267354490515), np.float64(0.05582095783711688), np.float64(0.05581519061809395), np.float64(0.05580943377091164), np.float64(0.055803687274578614), np.float64(0.05579795110818212), np.float64(0.05579222525088745), np.float64(0.055786509681936956), np.float64(0.05578080438064925), np.float64(0.05577510932641848), np.float64(0.05576942449871346), np.float64(0.055763749877076975), np.float64(0.05575808544112503), np.float64(0.05575243117054599), np.float64(0.05574678704509999), np.float64(0.05574115304461813), np.float64(0.055735529149001775), np.float64(0.05572991533822185), np.float64(0.0557243115923182), np.float64(0.05571871789139883), np.float64(0.05571313421563932), np.float64(0.05570756054528211), np.float64(0.055701996860635865), np.float64(0.055696443142074864), np.float64(0.055690899370038335), np.float64(0.05568536552502988), np.float64(0.05567984158761686), np.float64(0.055674327538429685), np.float64(0.05566882335816142), np.float64(0.055663329027567085), np.float64(0.055657844527463085), np.float64(0.05565236983872668), np.float64(0.05564690494229538), np.float64(0.0556414498191665), np.float64(0.05563600445039652), np.float64(0.055630568817100635), np.float64(0.05562514290045211), np.float64(0.05561972668168197), np.float64(0.05561432014207832), np.float64(0.05560892326298588), np.float64(0.055603536025805575), np.float64(0.055598158411993996), np.float64(0.05559279040306291), np.float64(0.055587431980578784), np.float64(0.055582083126162425), np.float64(0.05557674382148841), np.float64(0.055571414048284674), np.float64(0.05556609378833211), np.float64(0.055560783023464094), np.float64(0.05555548173556606), np.float64(0.055550189906575106), np.float64(0.05554490751847952), np.float64(0.055539634553318486), np.float64(0.05553437099318153), np.float64(0.055529116820208266), np.float64(0.05552387201658793), np.float64(0.055518636564558965), np.float64(0.05551341044640875), np.float64(0.05550819364447313), np.float64(0.05550298614113609), np.float64(0.05549778791882936), np.float64(0.05549259896003212), np.float64(0.05548741924727061), np.float64(0.05548224876311773), np.float64(0.055477087490192804), np.float64(0.0554719354111612), np.float64(0.055466792508733924), np.float64(0.05546165876566746), np.float64(0.055456534164763226), np.float64(0.05545141868886745), np.float64(0.05544631232087083), np.float64(0.05544121504370806), np.float64(0.055436126840357744), np.float64(0.055431047693841926), np.float64(0.05542597758722593), np.float64(0.055420916503617974), np.float64(0.05541586442616892), np.float64(0.055410821338071965), np.float64(0.05540578722256242), np.float64(0.05540076206291734), np.float64(0.055395745842455345), np.float64(0.05539073854453634), np.float64(0.05538574015256118), np.float64(0.05538075064997147), np.float64(0.055375770020249314), np.float64(0.05537079824691705), np.float64(0.05536583531353694), np.float64(0.05536088120371103), np.float64(0.05535593590108084), np.float64(0.05535099938932713), np.float64(0.055346071652169704), np.float64(0.0553411526733671), np.float64(0.05533624243671647), np.float64(0.05533134092605322), np.float64(0.055326448125250914), np.float64(0.05532156401822096), np.float64(0.05531668858891247), np.float64(0.055311821821311946), np.float64(0.055306963699443185), np.float64(0.05530211420736701), np.float64(0.055297273329180996), np.float64(0.05529244104901939), np.float64(0.0552876173510529), np.float64(0.05528280221948834), np.float64(0.05527799563856866), np.float64(0.055273197592572584), np.float64(0.05526840806581448), np.float64(0.055263627042644155), np.float64(0.055258854507446706), np.float64(0.05525409044464235), np.float64(0.05524933483868614), np.float64(0.05524458767406786), np.float64(0.05523984893531189), np.float64(0.055235118606976955), np.float64(0.05523039667365596), np.float64(0.05522568311997589), np.float64(0.055220977930597534), np.float64(0.055216281090215466), np.float64(0.05521159258355773), np.float64(0.055206912395385714), np.float64(0.055202240510494154), np.float64(0.05519757691371069), np.float64(0.055192921589895944), np.float64(0.055188274523943294), np.float64(0.05518363570077869), np.float64(0.05517900510536053), np.float64(0.05517438272267951), np.float64(0.055169768537758505), np.float64(0.055165162535652366), np.float64(0.055160564701447826), np.float64(0.05515597502026334), np.float64(0.055151393477248956), np.float64(0.05514682005758613), np.float64(0.055142254746487665), np.float64(0.05513769752919755), np.float64(0.0551331483909908), np.float64(0.055128607317173346), np.float64(0.055124074293081866), np.float64(0.055119549304083755), np.float64(0.05511503233557687), np.float64(0.05511052337298953), np.float64(0.05510602240178027), np.float64(0.05510152940743782), np.float64(0.05509704437548093), np.float64(0.05509256729145828), np.float64(0.05508809814094827), np.float64(0.05508363690955906), np.float64(0.05507918358292834), np.float64(0.05507473814672324), np.float64(0.055070300586640204), np.float64(0.05506587088840496), np.float64(0.05506144903777225), np.float64(0.05505703502052585), np.float64(0.055052628822478474), np.float64(0.05504823042947156), np.float64(0.05504383982737522), np.float64(0.05503945700208816), np.float64(0.05503508193953754), np.float64(0.055030714625678864), np.float64(0.05502635504649593), np.float64(0.05502200318800065), np.float64(0.055017659036233034), np.float64(0.055013322577261034), np.float64(0.055008993797180404), np.float64(0.05500467268211479), np.float64(0.05500035921821539), np.float64(0.054996053391661005), np.float64(0.05499175518865794), np.float64(0.05498746459543984), np.float64(0.054983181598267664), np.float64(0.0549789061834296), np.float64(0.054974638337240846), np.float64(0.05497037804604376), np.float64(0.0549661252962075), np.float64(0.054961880074128146), np.float64(0.0549576423662285), np.float64(0.054953412158958034), np.float64(0.054949189438792796), np.float64(0.05494497419223534), np.float64(0.05494076640581463), np.float64(0.05493656606608597), np.float64(0.05493237315963089), np.float64(0.05492818767305708), np.float64(0.05492400959299837), np.float64(0.05491983890611449), np.float64(0.05491567559909121), np.float64(0.05491151965864005), np.float64(0.05490737107149833), np.float64(0.05490322982442909), np.float64(0.054899095904220915), np.float64(0.05489496929768798), np.float64(0.05489084999166989), np.float64(0.05488673797303166), np.float64(0.054882633228663574), np.float64(0.05487853574548118), np.float64(0.054874445510425175), np.float64(0.05487036251046136), np.float64(0.054866286732580524), np.float64(0.05486221816379847), np.float64(0.05485815679115577), np.float64(0.0548541026017179), np.float64(0.054850055582575), np.float64(0.05484601572084191), np.float64(0.0548419830036581), np.float64(0.05483795741818747), np.float64(0.05483393895161846), np.float64(0.0548299275911639), np.float64(0.054825923324060916), np.float64(0.05482192613757092), np.float64(0.05481793601897949), np.float64(0.05481395295559637), np.float64(0.05480997693475535), np.float64(0.05480600794381422), np.float64(0.0548020459701547), np.float64(0.054798091001182415), np.float64(0.05479414302432678), np.float64(0.054790202027040935), np.float64(0.05478626799680179), np.float64(0.05478234092110976), np.float64(0.05477842078748891), np.float64(0.0547745075834868), np.float64(0.054770601296674395), np.float64(0.05476670191464608), np.float64(0.05476280942501958), np.float64(0.054758923815435796), np.float64(0.05475504507355896), np.float64(0.05475117318707636), np.float64(0.0547473081436984), np.float64(0.05474344993115854), np.float64(0.054739598537213205), np.float64(0.054735753949641676), np.float64(0.05473191615624621), np.float64(0.05472808514485178), np.float64(0.054724260903306156), np.float64(0.05472044341947975), np.float64(0.05471663268126573), np.float64(0.05471282867657969), np.float64(0.0547090313933599), np.float64(0.05470524081956701), np.float64(0.05470145694318413), np.float64(0.05469767975221677), np.float64(0.054693909234692674), np.float64(0.05469014537866194), np.float64(0.05468638817219683), np.float64(0.05468263760339178), np.float64(0.05467889366036329), np.float64(0.05467515633125), np.float64(0.05467142560421251), np.float64(0.05466770146743334), np.float64(0.054663983909116975), np.float64(0.054660272917489705), np.float64(0.05465656848079964), np.float64(0.05465287058731666), np.float64(0.05464917922533233), np.float64(0.05464549438315985), np.float64(0.054641816049134054), np.float64(0.05463814421161133), np.float64(0.05463447885896955), np.float64(0.05463081997960807), np.float64(0.05462716756194763), np.float64(0.05462352159443039), np.float64(0.054619882065519716), np.float64(0.054616248963700355), np.float64(0.05461262227747823), np.float64(0.05460900199538041), np.float64(0.054605388105955124), np.float64(0.054601780597771675), np.float64(0.05459817945942039), np.float64(0.05459458467951261), np.float64(0.05459099624668059), np.float64(0.05458741414957748), np.float64(0.0545838383768773), np.float64(0.054580268917274875), np.float64(0.05457670575948582), np.float64(0.05457314889224635), np.float64(0.054569598304313474), np.float64(0.0545660539844648), np.float64(0.054562515921498494), np.float64(0.05455898410423328), np.float64(0.054555458521508345), np.float64(0.05455193916218337), np.float64(0.05454842601513845), np.float64(0.05454491906927401), np.float64(0.05454141831351079), np.float64(0.054537923736789846), np.float64(0.054534435328072464), np.float64(0.0545309530763401), np.float64(0.054527476970594374), np.float64(0.054524006999857044), np.float64(0.054520543153169884), np.float64(0.05451708541959473), np.float64(0.054513633788213396), np.float64(0.054510188248127645), np.float64(0.05450674878845912), np.float64(0.05450331539834934), np.float64(0.054499888066959656), np.float64(0.05449646678347117), np.float64(0.054493051537084725), np.float64(0.05448964231702087), np.float64(0.05448623911251984), np.float64(0.05448284191284145), np.float64(0.054479450707265106), np.float64(0.05447606548508972), np.float64(0.054472686235633755), np.float64(0.054469312948235114), np.float64(0.0544659456122511), np.float64(0.05446258421705838), np.float64(0.05445922875205301), np.float64(0.05445587920665035), np.float64(0.05445253557028493), np.float64(0.05444919783241064), np.float64(0.05444586598250044), np.float64(0.054442540010046496), np.float64(0.05443921990456002), np.float64(0.0544359056555714), np.float64(0.054432597252629965), np.float64(0.05442929468530409), np.float64(0.054425997943181044), np.float64(0.05442270701586708), np.float64(0.05441942189298729), np.float64(0.05441614256418564), np.float64(0.05441286901912488), np.float64(0.05440960124748651), np.float64(0.054406339238970806), np.float64(0.05440308298329671), np.float64(0.054399832470201845), np.float64(0.054396587689442416), np.float64(0.054393348630793245), np.float64(0.05439011528404767), np.float64(0.05438688763901759), np.float64(0.054383665685533336), np.float64(0.0543804494134437), np.float64(0.054377238812615865), np.float64(0.05437403387293539), np.float64(0.054370834584306166), np.float64(0.05436764093665037), np.float64(0.054364452919908414), np.float64(0.05436127052403898), np.float64(0.05435809373901896), np.float64(0.05435492255484332)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.4 Step -4- Evaluate the Model:"
      ],
      "metadata": {
        "id": "U1338B_l2Qm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 8"
      ],
      "metadata": {
        "id": "MhDlN0yA2L0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(Y, Y_pred):\n",
        "    mse = np.mean((Y - Y_pred) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "TLl_6L1S2Nrj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 9"
      ],
      "metadata": {
        "id": "HRmeZ62F3MeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def r2(Y, Y_pred):\n",
        "  mean_y=np.mean(Y)\n",
        "  ss_tot=np.sum((Y - mean_y)**2)\n",
        "  ss_res=np.sum((Y-Y_pred)**2)\n",
        "  r2=1-(ss_res/ss_tot)\n",
        "  return r2"
      ],
      "metadata": {
        "id": "qvsSZNkE3OcZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1.5 Step -5- Main Function to Integrate All Steps:"
      ],
      "metadata": {
        "id": "8CuEGAVA3f02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 10"
      ],
      "metadata": {
        "id": "uTKGIx7G3bn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Cost Function\n",
        "def cost_function(X, Y, W):\n",
        "    m = len(Y)\n",
        "    Y_pred = X @ W\n",
        "    cost = np.sum((Y_pred - Y) ** 2) / (2 * m)\n",
        "    return cost\n",
        "\n",
        "# Gradient Descent\n",
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    cost_history = [0] * iterations\n",
        "    m = len(Y)\n",
        "\n",
        "    for iteration in range(iterations):\n",
        "        Y_pred = X @ W\n",
        "        loss = Y_pred - Y\n",
        "        dw = (X.T @ loss) / m\n",
        "        W = W - alpha * dw\n",
        "        cost = cost_function(X, Y, W)\n",
        "        cost_history[iteration] = cost\n",
        "\n",
        "    return W, cost_history\n",
        "\n",
        "# RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "    mse = np.mean((Y - Y_pred) ** 2)\n",
        "    return np.sqrt(mse)\n",
        "\n",
        "# R²\n",
        "def r2(Y, Y_pred):\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/Ai/student.csv\")\n",
        "\n",
        "    # Features and target\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "\n",
        "    # Corrected train_test_split\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Initialize weights and hyperparameters\n",
        "    W = np.zeros(X_train.shape[1])\n",
        "    alpha = 0.00001\n",
        "    iterations = 1000\n",
        "\n",
        "    # Train model\n",
        "    W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "\n",
        "    # Predictions\n",
        "    Y_pred = np.dot(X_test, W_optimal)\n",
        "\n",
        "    # Evaluation\n",
        "    model_rmse = rmse(Y_test, Y_pred)\n",
        "    model_r2 = r2(Y_test, Y_pred)\n",
        "\n",
        "    # Output\n",
        "    print(\"Final Weights: \", W_optimal)\n",
        "    print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "    print(\"RMSE on test set: \", model_rmse)\n",
        "    print(\"R-Squared on test set: \", model_r2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgGaYjVY3dVK",
        "outputId": "fa4b6501-9cf1-4d30-ffab-a696e07d1ffc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights:  [0.34973248 0.64484523]\n",
            "Cost History (First 10 iterations): [np.float64(2011.9142554734751), np.float64(1639.7141350925601), np.float64(1336.957481353757), np.float64(1090.6876393991413), np.float64(890.3653872086318), np.float64(727.4178946799879), np.float64(594.8718372335271), np.float64(487.0549625191084), np.float64(399.35333835029707), np.float64(328.0138929475418)]\n",
            "RMSE on test set:  5.224589785890596\n",
            "R-Squared on test set:  0.8868710151151797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise: 11"
      ],
      "metadata": {
        "id": "REeh2CAp4h2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cost Function\n",
        "def cost_function(X, Y, W):\n",
        "    m = len(Y)\n",
        "    Y_pred = X @ W\n",
        "    return np.sum((Y_pred - Y) ** 2) / (2 * m)\n",
        "\n",
        "# Gradient Descent\n",
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    cost_history = []\n",
        "    m = len(Y)\n",
        "    for _ in range(iterations):\n",
        "        Y_pred = X @ W\n",
        "        loss = Y_pred - Y\n",
        "        dw = (X.T @ loss) / m\n",
        "        W = W - alpha * dw\n",
        "        cost_history.append(cost_function(X, Y, W))\n",
        "    return W, cost_history\n",
        "\n",
        "# RMSE\n",
        "def rmse(Y, Y_pred):\n",
        "    return np.sqrt(np.mean((Y - Y_pred) ** 2))\n",
        "\n",
        "# R²\n",
        "def r2(Y, Y_pred):\n",
        "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
        "    ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "# Main Experiment\n",
        "def main():\n",
        "    data = pd.read_csv(\"/content/drive/MyDrive/Ai/student.csv\")\n",
        "    X = data[['Math', 'Reading']].values\n",
        "    Y = data['Writing'].values\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "    learning_rates = [0.0000001, 0.00001, 0.001, 0.1]\n",
        "    iterations = 1000\n",
        "\n",
        "    print(\"🔍 Learning Rate Experiment Results:\\n\")\n",
        "    for alpha in learning_rates:\n",
        "        W = np.zeros(X_train.shape[1])\n",
        "        W_opt, _ = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "        Y_pred = X_test @ W_opt\n",
        "        error = rmse(Y_test, Y_pred)\n",
        "        score = r2(Y_test, Y_pred)\n",
        "        print(f\"Learning Rate: {alpha}\")\n",
        "        print(f\"  ➤ RMSE: {error:.4f}\")\n",
        "        print(f\"  ➤ R² Score: {score:.4f}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxv2U4rJ4jd2",
        "outputId": "955470ad-1470-4811-9ebf-84c9140a7960"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Learning Rate Experiment Results:\n",
            "\n",
            "Learning Rate: 1e-07\n",
            "  ➤ RMSE: 26.9370\n",
            "  ➤ R² Score: -2.0072\n",
            "\n",
            "Learning Rate: 1e-05\n",
            "  ➤ RMSE: 5.2246\n",
            "  ➤ R² Score: 0.8869\n",
            "\n",
            "Learning Rate: 0.001\n",
            "  ➤ RMSE: nan\n",
            "  ➤ R² Score: nan\n",
            "\n",
            "Learning Rate: 0.1\n",
            "  ➤ RMSE: nan\n",
            "  ➤ R² Score: nan\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/tmp/ipython-input-3670391161.py:5: RuntimeWarning: overflow encountered in square\n",
            "  return np.sum((Y_pred - Y) ** 2) / (2 * m)\n",
            "/tmp/ipython-input-3670391161.py:14: RuntimeWarning: overflow encountered in matmul\n",
            "  dw = (X.T @ loss) / m\n",
            "/tmp/ipython-input-3670391161.py:15: RuntimeWarning: invalid value encountered in subtract\n",
            "  W = W - alpha * dw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I experimented with different learning rates. A very small rate led to slow learning and underfitting, while a large rate caused instability and poor predictions. The best performance was observed around α = 0.001, which balanced speed and accuracy."
      ],
      "metadata": {
        "id": "Y3-nDF0n5JEJ"
      }
    }
  ]
}